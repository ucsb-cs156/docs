---
parent: Liquibase
grand_parent: Topics
layout: default
title: "liquibase: adding a table"
description:  "How to add a new table"
indent: true
---

# {{page.title}}

When not using liquibase, to add a new table, you simple create the `@Entity` class and the `@Repository` class.

When using liquibase, there is an additional step: you must generate the changelog file and store it in `src/main/resources/db`

You can generate the changelog by hand, but it is easier to use a tool to do it.   

# Example: Adding a `course` table

## Step 1: Create the `@Entity` and `@Repository` classes

As an example, suppose you are adding the following `@Entity` (imports omitted to save space):

```java
@Data
@AllArgsConstructor
@NoArgsConstructor(access = AccessLevel.PROTECTED)
@Builder
@Entity(name = "courses")
public class Course {
  @Id
  @GeneratedValue(strategy = GenerationType.IDENTITY)
  private long id;

  private String name;
  private String school;
  private String term;
  private LocalDateTime start;
  private LocalDateTime end;
  private String githubOrg;
}
```

We also need the `@Repository` class, for example:

```java
@Repository
public interface CourseRepository extends CrudRepository<Course, Integer> {

}
```

Create these files first. Then you are ready for the next step.

## Step 2: Temporarily modify `application.properties` so that the table is created

Next, find this section in `src/main/resources/application.properties`:

```
# There are two settings for spring.jpa.hibernate.ddl-auto, namely "update" and "none"
# Normally the value should be none, because we are using liquibase to manage migrations
# However, temporarily, the value may need to be "update" when you want tables created
# or updated automatically by Spring Boot.

spring.jpa.hibernate.ddl-auto=none    
# spring.jpa.hibernate.ddl-auto=update 
```

As explained in the comment, you need to temporarily switch this to: 

```
# spring.jpa.hibernate.ddl-auto=none   
spring.jpa.hibernate.ddl-auto=update 
```

And then run the command:
```
mvn spring-boot:run
```

You do not need to run the frontend.  The web browser will show this:

<img width="668" alt="image" src="https://github.com/ucsb-cs156/ucsb-cs156.github.io/assets/1119017/a63340ad-cf3b-4e56-a3b6-b166bd38c46b">

Click on the link for the h2-console and connect.  You should see the new database tables have been created, for example:

<img width="477" alt="image" src="https://github.com/ucsb-cs156/ucsb-cs156.github.io/assets/1119017/195d4cfe-b7d2-4a33-ae17-b35ec12ad046">

<img width="211" alt="image" src="https://github.com/ucsb-cs156/ucsb-cs156.github.io/assets/1119017/75abb587-12ff-4498-be46-d5d962f9cd55">

## Step 3: Change `application.properties` back

Now CTRL/C to stop the backend running, and change the value in `src/main/resources/application.properties`: back to:

```
spring.jpa.hibernate.ddl-auto=none    
# spring.jpa.hibernate.ddl-auto=update 
```

## Step 4: Choose a filename for the change log


We next want to generate a change log, so we much choose a filename.  The choice is important, because change logs in multiple file are applied
in the order of their filenames (in alphabetical order, or more precisely, in "lexicographic order".)   We have chosen a naming convention to 
ensure the migrations are applied in the order we intend.

Look in the directory `src/main/resources/db/migration/changes/` to see what the next avaiable number is; the naming convention we use in CS156 is a four digit number followed by an underscore, followed by a brief title that describes the migration.   For example, we see: 

<img width="465" alt="image" src="https://github.com/ucsb-cs156/ucsb-cs156.github.io/assets/1119017/21014506-a632-48c3-a3ce-4e85c5e64648">

The next available number is `0005_` and we are defining the course table, so we choose the name `0005_CreateCourseTable.json`.

The full name is `src/main/resources/db/migration/changes/0005_CreateCourseTable.json`.

## Step 5: Generate the full migration change log

The next step is to generate a full change log that represents the entire database; we'll then edit it down to only the change that we want.

We can do that with the following command:

```sh
mvn liquibase:generateChangeLog -Dliquibase.outputChangeLogFile=src/main/resources/db/migration/changes/0005_CreateCourseTable.json
```

## Step 6: Edit the full change log into the one you need

Now look over the file `0005_CreateCourseTable.json` that was generated. You'll see that it is actually now a set of changes that
would produce the entire database.  You'l need to:

* edit that down to just the changes that you are introducing in the `@Entity` and `@Repoisotry` classes that are in your pull request
* change some of the autogenerated ids to ones that match the course naming conventions

In this example, the few lines of the file look like this:

```json
{ "databaseChangeLog": [
  {
    "changeSet": {
      "id": "1699899121513-1",
      "author": "pconrad (generated)",
      "changes": [
```
Make these changes (you can look at other migration files already in the project for examples):

| Before | After | Explanation |
|-|-|-|
| `"id": "1699899121513-1"` | `"id": "changeset-0005` | This name matches the filename. If we have multiple changesets in the same file, we can name them `changeset-0005a`, `changeset-0005b`, etc |
|  `"author": "pconrad (generated)",` | `  "author": "pconrad",` | The github id of the author of the change is sufficient.  By the time we are done, this will no longer be the generated code |

Scrolling down further, we see that this first changeset is the creation of the Courses table, which is one of the two things we want to keep in this migration.

```json
"changes": [
        {
          "createTable": {
            "columns": [
              {
                "column": {
                  "autoIncrement": true,
                  "constraints": {
                    "primaryKey": true,
                    "primaryKeyName": "CONSTRAINT_6"
                  },
                  "name": "ID",
                  "type": "BIGINT"
                }
              },
              {
                "column": {
                  "name": "END",
                  "type": "TIMESTAMP"
                }
              },
              {
                "column": {
                  "name": "GITHUB_ORG",
                  "type": "VARCHAR(255)"
                }
              },
              {
                "column": {
                  "name": "NAME",
                  "type": "VARCHAR(255)"
                }
              },
              {
                "column": {
                  "name": "SCHOOL",
                  "type": "VARCHAR(255)"
                }
              },
              {
                "column": {
                  "name": "START",
                  "type": "TIMESTAMP"
                }
              },
              {
                "column": {
                  "name": "TERM",
                  "type": "VARCHAR(255)"
                }
              }]
            ,
            "tableName": "COURSES"
          }
        }]
```

Scrolling down further, we see another changeset; this one is for the `CoursesStaff` table.  We'll keep it too, but change the ids

Original:
```json
 {
    "changeSet": {
      "id": "1699899121513-2",
      "author": "pconrad (generated)",
```

We'll update this as follows.

```
 {
    "changeSet": {
      "id": "changeset-0005b",
      "author": "pconrad",
```

We also change the first id to `"changeset-0005a"` now that there are two of them.

As we look through the rest of the file, we see that it pertains to tables that were already in the database, we we simply:
* remove the remaining change sets
* remove the trailing comma on the last change set.

We are left with the following as our changeset:

```json
{ "databaseChangeLog": [
  {
    "changeSet": {
      "id": "changeset-0005a",
      "author": "pconrad",
      "changes": [
        {
          "createTable": {
            "columns": [
              {
                "column": {
                  "autoIncrement": true,
                  "constraints": {
                    "primaryKey": true,
                    "primaryKeyName": "CONSTRAINT_6"
                  },
                  "name": "ID",
                  "type": "BIGINT"
                }
              },
              {
                "column": {
                  "name": "END",
                  "type": "TIMESTAMP"
                }
              },
              {
                "column": {
                  "name": "GITHUB_ORG",
                  "type": "VARCHAR(255)"
                }
              },
              {
                "column": {
                  "name": "NAME",
                  "type": "VARCHAR(255)"
                }
              },
              {
                "column": {
                  "name": "SCHOOL",
                  "type": "VARCHAR(255)"
                }
              },
              {
                "column": {
                  "name": "START",
                  "type": "TIMESTAMP"
                }
              },
              {
                "column": {
                  "name": "TERM",
                  "type": "VARCHAR(255)"
                }
              }]
            ,
            "tableName": "COURSES"
          }
        }]
      
    }
  },
  
  {
    "changeSet": {
      "id": "changeset-0005b",
      "author": "pconrad",
      "changes": [
        {
          "createTable": {
            "columns": [
              {
                "column": {
                  "autoIncrement": true,
                  "constraints": {
                    "primaryKey": true,
                    "primaryKeyName": "CONSTRAINT_2"
                  },
                  "name": "ID",
                  "type": "BIGINT"
                }
              },
              {
                "column": {
                  "name": "COURSE_ID",
                  "type": "BIGINT"
                }
              },
              {
                "column": {
                  "name": "GITHUB_ID",
                  "type": "INT"
                }
              }]
            ,
            "tableName": "COURSE_STAFF"
          }
        }]
      
    }
  }
  
]}
```

## Step 7: Add pre-conditions

The first four lines of each of our changesets for adding a new table now looks like this:

```json
 "changeSet": {
      "id": "changeset-0005a",
      "author": "pconrad",
      "changes": [
```

We now want to add some code between the `"author"` and `"changes"` keys that will make sure that the migration to create the table
doesn't run if the table already exists.  Here's what that looks like for the courses table:


```
      "preConditions": [
            {
              "onFail": "MARK_RAN"
            },
            {
              "not": [
                {
                  "tableExists": {
                    "tableName": "COURSES"
                  }
                }
              ]
            }
          ],
```

Copy and paste this into your migrations, changing the value of the `tableName` key to your table.  Afterwards, the entire file looks like this:

```json
{ "databaseChangeLog": [
  {
    "changeSet": {
      "id": "changeset-0005a",
      "author": "pconrad",
      "preConditions": [
        {
          "onFail": "MARK_RAN"
        },
        {
          "not": [
            {
              "tableExists": {
                "tableName": "COURSES"
              }
            }
          ]
        }
      ],
      "changes": [
        {
          "createTable": {
            "columns": [
              {
                "column": {
                  "autoIncrement": true,
                  "constraints": {
                    "primaryKey": true,
                    "primaryKeyName": "CONSTRAINT_6"
                  },
                  "name": "ID",
                  "type": "BIGINT"
                }
              },
              {
                "column": {
                  "name": "END",
                  "type": "TIMESTAMP"
                }
              },
              {
                "column": {
                  "name": "GITHUB_ORG",
                  "type": "VARCHAR(255)"
                }
              },
              {
                "column": {
                  "name": "NAME",
                  "type": "VARCHAR(255)"
                }
              },
              {
                "column": {
                  "name": "SCHOOL",
                  "type": "VARCHAR(255)"
                }
              },
              {
                "column": {
                  "name": "START",
                  "type": "TIMESTAMP"
                }
              },
              {
                "column": {
                  "name": "TERM",
                  "type": "VARCHAR(255)"
                }
              }]
            ,
            "tableName": "COURSES"
          }
        }]
      
    }
  },
  
  {
    "changeSet": {
      "id": "changeset-0005b",
      "author": "pconrad",
      "preConditions": [
        {
          "onFail": "MARK_RAN"
        },
        {
          "not": [
            {
              "tableExists": {
                "tableName": "COURSE_STAFF"
              }
            }
          ]
        }
      ],
      "changes": [
        {
          "createTable": {
            "columns": [
              {
                "column": {
                  "autoIncrement": true,
                  "constraints": {
                    "primaryKey": true,
                    "primaryKeyName": "CONSTRAINT_2"
                  },
                  "name": "ID",
                  "type": "BIGINT"
                }
              },
              {
                "column": {
                  "name": "COURSE_ID",
                  "type": "BIGINT"
                }
              },
              {
                "column": {
                  "name": "GITHUB_ID",
                  "type": "INT"
                }
              }]
            ,
            "tableName": "COURSE_STAFF"
          }
        }]
      
    }
  }
  
]}
```

## Step 8: Test by running `mvn spring-boot:run` on localhost

Next, on localhost, run `mvn spring-boot:run`.  This will check your syntax; if there's an error in your JSON, you'll find out now and hopefully
you can fix it and try again.

If your syntax is correct, the first time you do this, as part of startup, you should see something like this:

```
2023-11-13 10:31:24.989  INFO 44817 --- [  restartedMain] liquibase.changelog                      : Marking ChangeSet: db/migration/changes/0005_CreateCourseTable.json::changeset-0005a::pconrad ran despite precondition failure due to onFail='MARK_RAN': 
          db/migration/changelog-master.json : Not precondition failed

2023-11-13 10:31:24.997  INFO 44817 --- [  restartedMain] liquibase.changelog                      : Marking ChangeSet: db/migration/changes/0005_CreateCourseTable.json::changeset-0005b::pconrad ran despite precondition failure due to onFail='MARK_RAN': 
          db/migration/changelog-master.json : Not precondition failed

```

This lets you know that liquibase has marked the migration as "RAN" (meaning, it has already been run), so it won't try it again.  

CTRL/C and run `mvn spring-boot:run` on localhost a second time.  The second time, the output should be more like this:

```
2023-11-13 10:34:22.097  INFO 46913 --- [  restartedMain] liquibase.changelog                      : Reading resource: db/migration/changes/0001_CreateJobsTable.json
2023-11-13 10:34:22.196  INFO 46913 --- [  restartedMain] liquibase.changelog                      : Reading resource: db/migration/changes/0002_CreateUserEmailsTable.json
2023-11-13 10:34:22.199  INFO 46913 --- [  restartedMain] liquibase.changelog                      : Reading resource: db/migration/changes/0003_CreateUsersTable.json
2023-11-13 10:34:22.204  INFO 46913 --- [  restartedMain] liquibase.changelog                      : Reading resource: db/migration/changes/0004_AddIndexesAndForeignKeys.json
2023-11-13 10:34:22.208  INFO 46913 --- [  restartedMain] liquibase.changelog                      : Reading resource: db/migration/changes/0005_CreateCourseTable.json
```

This output shows that all of the migrations were processed in order with no errors.

You are now ready to try the migrations on a dokku instance, which is where they really matter. A localhost instance is only for development and testing; we typically don't store important real data there. But when we deploy to a dokku qa or dev instance, it's a practice run for when we roll out the new changes to a production database.  So if the database migration doesn't go smoothly when you roll it out to a dokku instance, it's a sign that things may go awry when your PR is merged into production, and the migration hits the production database.

So, pay close attention to whether the migration succeeds when rolling out to dokku.  A good way to start is with a clean database that matches what's on main.  You can do that by first resetting the database of your qa instance, and then redeploying the main branch to it, like this:

```
```
